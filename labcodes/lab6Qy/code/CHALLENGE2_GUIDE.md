# Challenge 2 完整指南：多调度算法实现与应用范围分析

## 执行摘要

本项目在 ucore OS 上实现了 **5 种基本调度算法**，并设计了完整的测试框架用于定量分析。

### 📊 已实现的调度算法

| # | 算法 | 文件 | 特点 | 适用场景 |
|---|------|------|------|--------|
| 1 | **FIFO** | `default_sched_fifo.c` | 最简单，无抢占 | 批处理、顺序任务 |
| 2 | **SJF** | `default_sched_sjf.c` | 最优周转时间 | 可预知长度的批处理 |
| 3 | **Priority** | `default_sched_priority.c` | 支持优先级 | 实时系统（有风险） |
| 4 | **RR** | `default_sched.c` | 完全公平，可抢占 | 分时系统、通用系统 |
| 5 | **Stride** | `default_sched_stride.c` | 比例公平，无饥荒 | 云计算、QoS 系统 |

### 🧪 设计的测试用例

```
user/test_uniform_load.c       → 均匀负载：测试公平性
user/test_variable_length.c    → 变长任务：测试 SJF 效果
user/test_priority_queue.c     → 优先级：测试优先级支持
user/test_mixed_workload.c     → 混合：综合测试
user/test_sequential_arrival.c → 顺序到达：实时特性
```

---

## 第一部分：快速开始

### 编译和运行特定调度器

```bash
cd /home/winking/courses/os-riscv/lab6/code

# 步骤 1：选择调度器
# 编辑 kern/schedule/sched.c 第 14 行：
# #define SCHED_CLASS SCHED_RR  (改为 SCHED_FIFO, SCHED_SJF, 等)

# 步骤 2：编译
make clean && make

# 步骤 3：运行
make qemu

# 步骤 4：查看结果
# 在 QEMU 输出中观察进程执行顺序、完成时间等
```

### 可选的调度器定义

```c
// 在 kern/schedule/sched.c 中修改这行来选择调度器：
#define SCHED_CLASS SCHED_RR       // Round Robin (默认)
#define SCHED_CLASS SCHED_FIFO     // First In First Out
#define SCHED_CLASS SCHED_SJF      // Shortest Job First  
#define SCHED_CLASS SCHED_PRIORITY // Static Priority
#define SCHED_CLASS SCHED_STRIDE   // Stride (Proportional Fair)
```

---

## 第二部分：详细分析

### 🎯 各算法的适用范围

#### 1️⃣ FIFO (First In First Out)

```
📋 实现：kern/schedule/default_sched_fifo.c
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

📊 性能指标：
  • 上下文切换：最少（仅 I/O 等待时）
  • 平均周转时间：最差（特别是混合长短任务）
  • 响应时间：最差
  • 公平性：无（严格顺序）
  
💡 算法原理：
  1. 进程按到达顺序加入队列
  2. 执行队列头部的进程直到完成
  3. 无时间片限制、无抢占
  
📚 适用场景：
  ✓ 单道批处理系统（传统大型机）
  ✓ 固定工作流程的嵌入式系统
  ✓ 离线数据处理（无用户交互）
  ✓ 简单的实验操作系统
  
  ✗ 交互式系统（响应慢）
  ✗ 多用户系统（不公平）
  ✗ 实时系统（响应时间无界）
  
⚠️ 典型问题：
  Convoy Effect（车队效应）
  ┌─────────────────────────────────┐
  │ CPU 密集(100ms) → 4 个 I/O(5ms) │
  │                   ↑              │
  │        所有 I/O 任务阻塞，等待  │
  └─────────────────────────────────┘
  
💾 实现复杂度：⭐ (最简单)
  代码行数：~50 行
  数据结构：单个链表
  操作复杂度：O(1)
  
📈 性能示例：
  3 个任务 (3,6,9) 执行：
  FIFO: P1(3) → P2(6) → P3(9)
  平均周转时间 = 10
  平均等待时间 = 4
```

---

#### 2️⃣ SJF (Shortest Job First)

```
📋 实现：kern/schedule/default_sched_sjf.c
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

📊 性能指标：
  • 平均周转时间：⭐⭐⭐⭐⭐ (最优)
  • 平均等待时间：⭐⭐⭐⭐⭐ (最优)
  • 响应时间：差
  • 公平性：无（短任务优先）
  • 数学证明：在非抢占模式下最优
  
💡 算法原理：
  1. 按任务长度排序（从短到长）
  2. 优先运行最短的任务
  3. 完成后再排序，选择下一个最短任务
  
📚 适用场景：
  ✓ 可预知任务长度的批处理系统
  ✓ 网络服务中的短连接处理（DNS, HTTP)
  ✓ 分布式计算框架（MapReduce, Spark）
  ✓ 数据库查询优化器
  
  ✗ 任务长度未知的系统
  ✗ 长短任务频繁交替
  ✗ 实时系统（需要实时性保证）
  ✗ 长任务容易饥荒
  
⚠️ 典型问题：
  Starvation of Long Jobs（长任务饥荒）
  ┌─────────────────────────────────┐
  │ 短任务不断到达                   │
  │ ├─ T=0: Job A(长,100ms)开始      │
  │ ├─ T=1: Job B(短,5ms)到达→立即  │
  │ ├─ T=6: Job C(短,5ms)到达→立即  │
  │ ├─ T=11: Job D(短,5ms)到达→立即 │
  │ ...Job A 永远无法完成！          │
  └─────────────────────────────────┘
  
💻 实现方法（我们的实现）：
  使用 time_slice 作为任务长度估计
  
  预测公式：τ_{n+1} = α·t_n + (1-α)·τ_n
  
  α = 0.5（平滑系数）
  t_n = 第 n 次实际运行时间
  τ_n = 第 n 次预测时间
  
💾 实现复杂度：⭐⭐ (中等)
  代码行数：~50 行
  数据结构：排序链表
  enqueue 操作：O(n) 排序插入
  pick_next 操作：O(1)
  
📈 性能示例：
  3 个任务 (3,6,9) 执行（必须是最优顺序）：
  SJF: P1(3) → P2(6) → P3(9)
  平均周转时间 = 10 (最优)
  
  若顺序不同 (9,6,3)：
  FIFO: P1(9) → P2(6) → P3(3)
  平均周转时间 = 14 (差)
  
  改进：(14-10)/14 ≈ 28% 性能提升！
```

---

#### 3️⃣ Priority (静态优先级)

```
📋 实现：kern/schedule/default_sched_priority.c
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

📊 性能指标：
  • 支持优先级：⭐⭐⭐⭐⭐ (完整)
  • 响应时间（高优先级）：⭐⭐⭐⭐⭐
  • 公平性：✗ (分层的)
  • 饥荒风险：⭐⭐⭐⭐⭐ (极高)
  
💡 算法原理：
  1. 多个优先级队列（通常 32-128 级）
  2. 从最高优先级队列取进程
  3. 该队列为空，才看下一级
  4. 同级内 FIFO
  
📚 适用场景：
  ✓ 实时系统（非硬实时）
  ✓ 多级应用（数据库、媒体、日志）
  ✓ 操作系统内核（系统任务 > 用户任务）
  
  ✗ 所有任务同等重要
  ✗ 需要公平性的系统
  ✗ 无法合理分配优先级的场景
  
⚠️ 严重问题：饥荒 (Starvation)

  [P1-高优先级]
  [P1-高优先级]  ← 不断到达新的高优先级任务
  [P1-高优先级]
  ...
  [P2-低优先级] ← 永远无法执行！

  ✅ 解决方案：优先级老化 (Aging)
  
  每个调度周期（如 100ms）：
  ├─ 高优先级任务优先级 -1
  ├─ 中优先级任务优先级 -1
  └─ 低优先级任务不变（或 +1）
  
  结果：低优先级任务逐渐升级，最终有机会运行
  
💾 实现复杂度：⭐⭐ (中等)
  代码行数：~60 行
  数据结构：多个排序链表（按优先级）
  时间复杂度：O(p) 其中 p = 优先级数
  
📈 性能示例（无老化）：
  5 个进程，优先级 (1,2,3,4,5)，每个 100 时间单位：
  
  执行顺序：P5(5) → P4(4) → P3(3) → P2(2) → P1(1)
  完成时间：500 (总时间相同)
  
  但响应时间分布极不均匀：
  ├─ P5: 响应时间 = 0    ✓
  ├─ P4: 响应时间 = 100  
  ├─ P3: 响应时间 = 200  
  ├─ P2: 响应时间 = 300  
  └─ P1: 响应时间 = 400  ✗ (太长)
```

---

#### 4️⃣ RR (Round Robin)

```
📋 实现：kern/schedule/default_sched.c (已有，Challenge 1)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

📊 性能指标：
  • 公平性：⭐⭐⭐⭐⭐ (完全)
  • 响应时间：⭐⭐⭐⭐ (可预测)
  • 无饥荒：⭐⭐⭐⭐⭐ (保证)
  • 平均周转时间：中等
  
💡 算法原理：
  1. 分配时间片 T (通常 10-100ms，我们用 5)
  2. 每个进程轮流执行时间片 T
  3. 时间片耗尽，强制切换到下一进程
  4. 所有进程在队列尾重新排队
  
📚 适用场景：
  ✓ 分时系统（多用户，每个用户轮流使用 CPU）
  ✓ 现代多任务操作系统（Windows, Linux, macOS）
  ✓ 网络服务器（Web, 数据库）
  ✓ 交互式应用（IDE, 编辑器）
  ✓ **通用操作系统默认选择**
  
  ✗ 没有进程到达（浪费时间片）
  ✗ 对优先级敏感的系统
  ✗ 硬实时系统（不保证任务截止时间）
  
💡 时间片大小的权衡：

  时间片 = 1ms:
  ├─ ✓ 响应时间好
  ├─ ✓ 交互性好
  └─ ✗ 上下文切换频繁（30-50% 开销）
  
  时间片 = 100ms:
  ├─ ✓ 上下文切换少（1-2% 开销）
  ├─ ✓ 缓存利用率高
  └─ ✗ 响应时间差
  
  时间片 = 10-50ms: (通常的选择)
  ├─ ✓ 响应时间可接受
  ├─ ✓ 上下文切换成本合理
  └─ ✓ 性能和交互性平衡
  
📊 响应时间分析：
  
  假设有 N 个进程，时间片 T
  
  ├─ 最好情况：T (进程在队首)
  ├─ 最坏情况：(N-1)×T (进程在队尾)
  └─ 平均情况：N×T/2
  
  例：5 个进程，T=10ms
  ├─ 最坏响应时间 = 4×10 = 40ms ✓
  ├─ 平均响应时间 = 5×10/2 = 25ms
  └─ 保证每个进程每 50ms 至少得到 10ms CPU
  
💾 实现复杂度：⭐⭐ (中等)
  代码行数：~50 行
  数据结构：循环链表 + time_slice 计数器
  时间复杂度：O(1)
  
📈 性能示例：
  5 个进程，各 100 时间单位，时间片 10：
  
  P1 → P2 → P3 → P4 → P5 → P1 → ...
  ├─ 轮转周期 = 5×10 = 50ms
  ├─ 每个进程每 50ms 得到 10ms
  └─ 完成时间 ≈ 100×5/5 = 500ms（相对平衡）
  
🏆 优势总结：
  1. 完全公平：所有进程获得相等时间
  2. 响应时间可预测
  3. 无进程饥荒
  4. 对任务长度无假设
  5. 公式简单，实现容易
  6. 现代 OS 的标准选择
```

---

#### 5️⃣ Stride (步幅调度)

```
📋 实现：kern/schedule/default_sched_stride.c
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

📊 性能指标：
  • 比例公平：⭐⭐⭐⭐⭐ (完美)
  • 优先级支持：⭐⭐⭐⭐⭐ (灵活)
  • 无饥荒：⭐⭐⭐⭐⭐ (保证)
  • 响应时间：⭐⭐⭐⭐ (可预测)
  
💡 算法原理（关键概念）：

  stride = BIG_STRIDE / priority
  
  每次调度：选择 pass 最小的进程
  执行后：pass += stride
  
  结果：CPU 时间分配 ∝ 优先级
  
📊 数学证明（比例公平性）：

  定理：进程 i 获得的 CPU 时间 / 进程 j 获得的 CPU 时间
        = 优先级 i / 优先级 j
  
  证明概要：
  ├─ stride_i = BIG_STRIDE / priority_i
  ├─ stride_j = BIG_STRIDE / priority_j
  ├─ 执行 n_i 次后：pass_i = n_i × stride_i
  ├─ 执行 n_j 次后：pass_j = n_j × stride_j
  ├─ 平衡时：n_i × stride_i ≈ n_j × stride_j
  ├─ 得：n_i × (BIG_STRIDE/p_i) ≈ n_j × (BIG_STRIDE/p_j)
  └─ 化简：n_i / n_j ≈ p_i / p_j ✓
  
📚 适用场景（最适合）：
  ✓ 云计算/虚拟化（VM 资源分配）
  ✓ 容器编排（Kubernetes Pod 调度）
  ✓ QoS 保证系统（流媒体、VoIP）
  ✓ 多租户数据库
  ✓ 任何需要"公平"分享 CPU 的场景
  
  实例：
  ┌────────────────────────────────┐
  │ 云数据中心 CPU 分配             │
  ├────────────────────────────────┤
  │ VM1(数据库):    P=5 → 50% CPU  │
  │ VM2(应用):      P=3 → 30% CPU  │
  │ VM3(备份):      P=2 → 20% CPU  │
  └────────────────────────────────┘
  
  Stride 自动精确实现这个比例！
  
💾 实现复杂度：⭐⭐⭐⭐ (较复杂)
  代码行数：~100 行
  数据结构：最小堆（skew_heap）
  时间复杂度：
  ├─ enqueue: O(log n)
  ├─ dequeue: O(log n)
  ├─ pick_next: O(1)
  └─ proc_tick: O(1)
  
🔧 实现细节：

  // BIG_STRIDE 选择很关键
  #define BIG_STRIDE 0x7FFFFFFF  // 2^31-1
  
  选择理由：
  ├─ 足够大，避免溢出
  ├─ uint32_t 范围内
  └─ 保证整数除法精度
  
  // 初始化
  proc->lab6_stride = 0      // 新进程从 0 开始
  proc->lab6_priority = 1-5  // 用户设置的优先级
  
  // 每次时间片耗尽后更新
  if (proc->time_slice == 0) {
      proc->lab6_stride += BIG_STRIDE / proc->lab6_priority;
  }
  
📊 执行流程示例：

  初始：3 个进程，优先级 (5,3,1)，BIG_STRIDE=900
  
  ┌────┬────────────┬──────┐
  │ P# │ Priority   │ Stride
  ├────┼────────────┼──────┤
  │ P1 │ 5          │ 900/5 = 180
  │ P2 │ 3          │ 900/3 = 300
  │ P3 │ 1          │ 900/1 = 900
  └────┴────────────┴──────┘
  
  调度顺序（选择 pass 最小的）：
  
  轮 1: P1(0), P2(0), P3(0) → 选 P1, pass=180
  轮 2: P2(0), P3(0), P1(180) → 选 P2, pass=300
  轮 3: P3(0), P1(180), P2(300) → 选 P3, pass=900
  轮 4: P1(180), P2(300), P3(900) → 选 P1, pass=360
  轮 5: P2(300), P1(360), P3(900) → 选 P2, pass=600
  轮 6: P1(360), P2(600), P3(900) → 选 P1, pass=540
  轮 7: P2(600), P1(540), P3(900) → 选 P1, pass=720
  轮 8: P2(600), P1(720), P3(900) → 选 P2, pass=900
  轮 9: P1(720), P2(900), P3(900) → 选 P1, pass=900
  
  最终执行次数：
  P1: 5 次 (55.6%) → 目标 5/9 ≈ 55.6% ✓
  P2: 3 次 (33.3%) → 目标 3/9 ≈ 33.3% ✓
  P3: 1 次 (11.1%) → 目标 1/9 ≈ 11.1% ✓
  
  完美按比例分配！
  
🏆 优势总结：
  1. 比例公平：CPU 时间 = 优先级比例
  2. 无饥荒：即使优先级最低仍会定期运行
  3. 灵活优先级：支持任意优先级值
  4. 可预测：响应时间与优先级相关
  5. 平衡：既有优先级灵活性，又有公平保证
  
  Google, Amazon, Alibaba 等大规模云计算
  都使用类似原理进行虚拟机和容器调度！
```

---

### 🎓 对比速查表

#### 按应用场景

```
你的系统需求是什么？
│
├─【需要最小周转时间】
│  → SJF（如果知道任务长度）
│  → RR（如果不知道）
│
├─【需要最小响应时间】
│  → RR 或 Stride
│  → 时间片 10-50ms
│
├─【需要严格优先级】
│  → Priority（简单，但有风险）
│  → Stride（推荐，无饥荒）
│
├─【需要完全公平】
│  → RR （完全相等）
│  → Stride（按比例）
│
├─【需要最少上下文切换】
│  → FIFO
│  → Priority（无抢占）
│
└─【生产系统推荐】
   → RR（通用服务器）
   → Stride（云计算）
   → MLFQ（综合操作系统）
```

#### 按性能指标优化

```
目标指标          | 首选      | 次选     | 备注
─────────────────|----------|---------|──────────────────
平均周转时间最小   | SJF      | FIFO    | 需要预知长度
平均等待时间最小   | SJF      | RR      | 数学最优
响应时间最小       | RR       | Stride  | 时间片很关键
响应时间一致       | RR       | Stride  | 标准差最小
支持优先级         | Stride   | Priority| Stride 无饥荒
完全公平分配       | RR       | Stride  | 相对公平性
无进程饥荒         | RR       | Stride  | Priority 风险高
实现最简单         | FIFO     | SJF/RR  | 代码行数
性能开销最小       | FIFO     | Priority| 上下文切换
```

---

## 第三部分：实验验证

### 🔬 如何进行对比实验

#### 实验步骤

1. **选择调度器**
```bash
# 编辑 kern/schedule/sched.c 第 14 行
# 改变 #define SCHED_CLASS 的值
```

2. **编译**
```bash
make clean && make
```

3. **运行测试**
```bash
make qemu
# 或运行特定测试
make run-test_uniform_load
```

4. **收集指标**
```bash
# 在 QEMU 输出中查看：
# - 进程执行顺序
# - 完成时间
# - 等待时间
# - 公平性（标准差）
```

#### 预期结果对比

```
测试：test_uniform_load (5个进程，各100K工作)

FIFO 结果：
  child 0: 完成，执行时间≈100K
  child 1: 完成，执行时间≈100K
  child 2: 完成，执行时间≈100K
  child 3: 完成，执行时间≈100K
  child 4: 完成，执行时间≈100K
  
  分析：完全顺序，完美顺序依赖
  ✓ 上下文切换最少
  ✗ 完全不公平（早到的进程等待）

RR 结果：
  所有进程交替运行，均匀分布
  每个进程执行时间≈100K
  完成时间差异 < 1%
  
  分析：完全公平，轮转执行
  ✓ 公平性完美
  ✓ 响应时间有界
  ✗ 上下文切换频繁

SJF 结果：
  （如果能知道长度）执行顺序优化
  平均周转时间最小
  
  分析：理论最优
  ✓ 周转时间最优
  ✗ 需要预知长度

Priority 结果：
  高优先级进程全部运行，低优先级延迟
  可能出现饥荒
  
  分析：严格分层
  ✓ 高优先级响应快
  ✗ 低优先级可能无法运行

Stride 结果：
  按优先级比例分配 CPU
  所有进程都能运行，无饥荒
  
  分析：按比例公平
  ✓ 无饥荒
  ✓ 比例精确
  ✓ 响应相对快
```

---

## 第四部分：进阶话题

### 🚀 调度器的未来方向

1. **适应性调度（Adaptive Scheduling）**
```
操作系统学习任务特征：
├─ CPU 密集 vs I/O 密集
├─ 短任务 vs 长任务
└─ 动态调整调度策略
```

2. **多级反馈队列（MLFQ）**
```
结合多个算法的优点：
├─ 一级（高）：RR，时间片小，快速响应
├─ 二级（中）：RR，时间片中等
└─ 三级（低）：SJF 或 FIFO，长任务
```

3. **多核感知调度（NUMA-aware）**
```
考虑：
├─ 处理器亲和性（CPU affinity）
├─ 内存本地性（memory locality）
└─ 核间同步成本
```

4. **能耗感知调度（Energy-aware）**
```
目标：
├─ 最小化功耗
├─ 合理利用动态频率调整（DVFS）
└─ 平衡性能和能耗
```

---

## 参考资源

### 📚 关键论文
- Waldspurger & Weihl: "The Stride Scheduling Algorithm" (1995)
- Lamport & Lamport: "Time, Clocks, and the Ordering of Events" (1978)

### 💾 操作系统中的实现
- **Linux**: CFS (Completely Fair Scheduler) - 改进的 RR + SJF
- **Windows**: Multi-level Feedback Queue (MLFQ)
- **macOS**: Mach Scheduler
- **Kubernetes**: Pod Priority and Preemption
- **Google Borg**: Hierarchical Resource Quotas

### 📖 推荐学习路径
1. 理解 FIFO（基础）
2. 学习 RR（现代标准）
3. 掌握 Stride（高级）
4. 研究 MLFQ（综合）
5. 探索自适应调度（前沿）

---

## 总结

通过实现和对比这 5 种调度算法，你已经深入理解了：

✅ **算法权衡**：响应时间 vs 周转时间 vs 公平性 vs 复杂度

✅ **系统设计**：不同系统对调度器的不同需求

✅ **性能优化**：如何根据工作负载选择合适的策略

✅ **设计模式**：Strategy 模式在系统中的应用

✅ **数学基础**：调度理论的证明和分析

这是**操作系统教学中最核心的内容**，也是工业界在设计实时系统、云计算平台、容器编排等系统时都会面临的问题。

**恭喜！你已经完成了 Challenge 2 的全部内容。** 🎉
